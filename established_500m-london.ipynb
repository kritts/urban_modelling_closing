{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "no such file or directory: '../data/MP14_SUBZONE_WEB_PL.shp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5f9acd14589c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# data.london.gov.uk/dataset/statistical-gis-boundary-files-london\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0msingapore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/MP14_SUBZONE_WEB_PL.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;31m# from the prj file: http://www.prj2epsg.org/epsg/27700\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0msingapore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingapore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'epsg:4277'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/geopandas/io/file.pyc\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[1;32m     20\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/fiona/__init__.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no such archive file: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no such file or directory: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[1;32m    168\u001b[0m                        \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvsi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: no such file or directory: '../data/MP14_SUBZONE_WEB_PL.shp'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from dit.divergences import jensen_shannon_divergence\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot as plt\n",
    "from dateutil.parser import parse\n",
    "from haversine import haversine\n",
    "import plotly.graph_objs as go\n",
    "from shapely.geometry import *\n",
    "from datetime import datetime  \n",
    "import plotly.plotly as py\n",
    "import scipy.stats as st\n",
    "import geopandas as gpd\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import operator\n",
    "import geojson\n",
    "import math \n",
    "import sys \n",
    "import dit\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "# data.london.gov.uk/dataset/statistical-gis-boundary-files-london \n",
    "singapore = gpd.read_file('../data/MP14_SUBZONE_WEB_PL.shp')\n",
    "# from the prj file: http://www.prj2epsg.org/epsg/27700\n",
    "singapore = singapore.to_crs({'init': 'epsg:4277'})   \n",
    "\n",
    "# path to data\n",
    "venues = \"../../../raw_data/venues/London_venues.txt\"\n",
    "transitions = \"../../../raw_data/transitions/London_transitions.txt\"\n",
    "\n",
    "# venue ID -> name\n",
    "venue_id_to_name = {} \n",
    "# venue ID -> coordinates for that venue\n",
    "venue_id_to_coords = {} \n",
    "# venue ID -> SPECIFIC category\n",
    "venue_id_to_category_specific = {} \n",
    "# venue ID -> GENERAL category\n",
    "venue_id_to_category_general = {} \n",
    "# venue ID -> opening date\n",
    "venue_id_to_opening = {}  \n",
    "\n",
    "### get all venues \n",
    "with open(venues, 'r') as f:\n",
    "    for rows in f:\n",
    "        rows = rows.split(\"\\t\")\n",
    "        # unique ID \n",
    "        ID = rows[0] \n",
    "        # name\n",
    "        name = rows[1]\n",
    "        venue_id_to_name[ID] = name \n",
    "        # coordinates \n",
    "        coordinates = (float(rows[2]), float(rows[3]))\n",
    "        venue_id_to_coords[ID] = coordinates  \n",
    "        # specific category\n",
    "        type_venue = rows[7]\n",
    "        venue_id_to_category_specific[ID] = type_venue  \n",
    "        # general categorgy\n",
    "        type_venue = rows[8]\n",
    "        venue_id_to_category_general[ID] = type_venue  \n",
    "        \n",
    "        # date\n",
    "        date = rows[9].strip()  \n",
    "        date_cleaned = datetime.strptime(date, '%Y-%m-%d')\n",
    "        venue_id_to_opening[ID] = date_cleaned\n",
    "        \n",
    "LIST_OF_VENUES = venue_id_to_opening.keys()\n",
    "\n",
    "# venue ID -> list of *FIRST* checkins to that venue       \n",
    "venue_id_to_times = {} \n",
    "with open(transitions, 'r') as f:\n",
    "    for rows in f:\n",
    "        rows = rows.split(\"\\t\")\n",
    "        location1 = rows[0]\n",
    "        time1 = rows[1] \n",
    "        if location1 in venue_id_to_coords:\n",
    "            venue_id_to_times.setdefault(location1, [])\n",
    "            time_cleaned = datetime.fromtimestamp(int(time1))\n",
    "            venue_id_to_times[location1].append(time_cleaned)\n",
    "             \n",
    "# venue id to the number of checkins to that venue \n",
    "venue_id_to_num = {}\n",
    "for v in LIST_OF_VENUES:\n",
    "    if v not in venue_id_to_times:\n",
    "        continue \n",
    "    venue_id_to_num[v] = len(venue_id_to_times[v])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "places_opened_to_num = {}\n",
    "for v in venue_id_to_opening: \n",
    "    if v not in venue_id_to_num: \n",
    "        continue \n",
    "    date = venue_id_to_opening[v]\n",
    "    year = date.year\n",
    "    month = date.month \n",
    "    places_opened_to_num[v] = venue_id_to_num[v]\n",
    "         \n",
    "# list of new venues that have at least 100 checkins \n",
    "venues_above_threshold = [venue for venue in places_opened_to_num if places_opened_to_num[venue] > 100]\n",
    "print len(venues_above_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'pickledump.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fc52533b8fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m    \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvenue_to_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \"\"\" \n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pickledump.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m    \u001b[0mvenue_to_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'pickledump.txt'"
     ]
    }
   ],
   "source": [
    " \n",
    "# This takes a long time. It gives us info about which venues are near other venues. \n",
    "\"\"\"\n",
    "from haversine import haversine\n",
    "print \"GOAL: \", len(venues_above_threshold)\n",
    "i = 0\n",
    "venue_to_set = {}\n",
    "for v in venues_above_threshold: \n",
    "    i += 1\n",
    "    venue_to_set.setdefault(v, set())\n",
    "    c1 = venue_id_to_coords[v]\n",
    "    for v2 in venue_id_to_coords: \n",
    "        if v2 == v: \n",
    "            continue\n",
    "        c2 = venue_id_to_coords[v2]\n",
    "        distance = haversine(c1, c2)\n",
    "        if distance < .5:  \n",
    "            venue_to_set[v].add(v2) \n",
    "    if i % 1000 == 0: \n",
    "        print i\n",
    "   \n",
    " \n",
    "import cPickle\n",
    "\n",
    "with open(\"500m_nearby_venues_pickle_london.txt\", \"w\") as fp:\n",
    "    cPickle.dump(venue_to_set, fp)\n",
    "\"\"\" \n",
    "with open(\"pickledump.txt\", \"r\") as fp:\n",
    "    venue_to_set = cPickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check if there's data last 6 months\n",
    "# is there less than 12 checkins after july 2013\n",
    "venues_closed = set()\n",
    "# whether venue is open or closed \n",
    "venue_to_status = {}\n",
    "for v in venues_above_threshold:\n",
    "    if v not in venue_id_to_times: \n",
    "        continue\n",
    "    times = venue_id_to_times[v]\n",
    "    checkins_after = 0\n",
    "    for date in times:\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        if year == 2013 and month > 6 or year > 2014:\n",
    "            checkins_after += 1 \n",
    "    if checkins_after <= 6: # less than one checkin a month\n",
    "        venues_closed.add(v)     \n",
    "        venue_to_status[v] = 0\n",
    "    else: \n",
    "        venue_to_status[v] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n"
     ]
    }
   ],
   "source": [
    "venue_to_surrdng_area = venue_to_set\n",
    "\n",
    "# when people end up at this ward, from where do they come?\n",
    "# that same ward or a different ward?\n",
    "venue_inflow_transitions = {}\n",
    "venue_outflow_transitions = {}\n",
    "#venue_within_transitions = {}\n",
    "\n",
    "venue_distance_entering = {}\n",
    "venue_distance_leaving = {}\n",
    "venue_speed_entering = {}\n",
    "venue_speed_leaving = {}\n",
    "  \n",
    "error_counter = 0\n",
    "i = 0\n",
    "with open(transitions, 'r') as f:\n",
    "    for rows in f: \n",
    "        i += 1 \n",
    "        if i % 1000000 == 0:\n",
    "            print i\n",
    "        rows = rows.split(\"\\t\")\n",
    "        location_1 = rows[0]\n",
    "        time1 = rows[1]\n",
    "        location_2 = rows[2]\n",
    "        time2 = rows[3]  \n",
    " \n",
    "        if location_1 not in venue_to_surrdng_area or location_2 not in venue_to_surrdng_area: \n",
    "            error_counter += 1\n",
    "            continue\n",
    "        if location_1 not in venue_id_to_coords or location_2 not in venue_id_to_coords: \n",
    "            continue\n",
    "\n",
    "        coords_1 = venue_id_to_coords[location_1]\n",
    "        coords_2 = venue_id_to_coords[location_2]\n",
    "        distance_current = haversine(coords_1, coords_2)\n",
    "\n",
    "        timeTravelled = int(time2) - int(time1)\n",
    "        timeTravelled = (timeTravelled / 60.0)/ 60.0\n",
    "        if timeTravelled > 0:\n",
    "            speed_current = distance_current / timeTravelled\n",
    "        else: \n",
    "            speed_current = 0\n",
    "\n",
    "        #\n",
    "        venue_outflow_transitions.setdefault(location_1, 0)\n",
    "        venue_outflow_transitions[location_1] += 1 \n",
    "\n",
    "        venue_speed_leaving.setdefault(location_1, [])\n",
    "        venue_speed_leaving[location_1].append(speed_current)\n",
    "        venue_distance_leaving.setdefault(location_1, [])\n",
    "        venue_distance_leaving[location_1].append(distance_current)\n",
    "\n",
    "        #\n",
    "        venue_inflow_transitions.setdefault(location_2, 0)\n",
    "        venue_inflow_transitions[location_2] += 1 \n",
    "\n",
    "        venue_speed_entering.setdefault(location_2, [])\n",
    "        venue_speed_entering[location_2].append(speed_current)\n",
    "        venue_distance_entering.setdefault(location_2, [])\n",
    "        venue_distance_entering[location_2].append(distance_current)\n",
    "\n",
    "        #if location_1 in v and location_2 in v:\n",
    "            #srrndng_to_num_within_transitions.setdefault(k, 0)\n",
    "            #srrndng_to_num_within_transitions[k] += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate entropy\n",
    "srrdng_to_entropy = {}\n",
    "for current_v in venue_to_surrdng_area:  \n",
    "    dict_cat_to_count = {}  \n",
    "    \n",
    "    list_venues = venue_to_surrdng_area[current_v] \n",
    "    for surrounding_v in list_venues: \n",
    "        categ = venue_id_to_category_general[surrounding_v]\n",
    "        dict_cat_to_count.setdefault(categ, 0)\n",
    "        dict_cat_to_count[categ] += 1\n",
    "        \n",
    "    sum_values = sum(dict_cat_to_count.values())\n",
    "    perc_dict = {}\n",
    "    for raw_vals in dict_cat_to_count: \n",
    "        perc_dict[raw_vals] = dict_cat_to_count[raw_vals] / float(sum_values)\n",
    "    \n",
    "    sum_vals = 0\n",
    "    for k, perc in perc_dict.items():  \n",
    "        sum_vals += perc * math.log(perc) \n",
    "    sum_vals *= -1\n",
    "    if len(perc_dict) != 0:\n",
    "        entropy = sum_vals / len(perc_dict)\n",
    "    else:\n",
    "        entropy = 0\n",
    "    srrdng_to_entropy[current_v] = entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import csv\n",
    "venue_to_kas_status = {}\n",
    "with open(\"london-venues-wlabel.csv\", \"rb\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        venue_to_kas_status[row[0]] = row[6] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python2.7/site-packages/numpy/core/_methods.py:135: RuntimeWarning:\n",
      "\n",
      "Degrees of freedom <= 0 for slice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_general = list(set(venue_id_to_category_general.values()))\n",
    "all_specific = list(set(venue_id_to_category_specific.values()))\n",
    "\n",
    "myData = np.array([[\"venue\", \"in\", \"out\", \\\n",
    "                    \"ratio in/out\", \"distance\",\"speed\",\"dis_std\", \"spe_std\", \"dis_lv\", \\\n",
    "                    \"spe_lv\", \"dis_lv_std\", \"spe_lv_std\", \"spec\", \"gen\", \\\n",
    "                    \"spec_count\", \"gen_count\", \"all_count\", \"spec_gen\", \"gen_all\", \"entropy\",\"closed or open\"]])\n",
    "NUM_FEATURES = 20\n",
    "count = 0\n",
    "\n",
    "for new_venue in venues_above_threshold: \n",
    "    # travel out of city bounds \n",
    "    \n",
    "    if new_venue not in venue_inflow_transitions or new_venue not in venue_outflow_transitions: \n",
    "        continue \n",
    "        \n",
    "    inner = np.array([]) \n",
    "    surrounding = venue_to_surrdng_area[new_venue]\n",
    "    \n",
    "    inflow_sum = 0\n",
    "    outflow_sum = 0 \n",
    "    distance_enter = []\n",
    "    distance_leave = []\n",
    "    speed_enter = []\n",
    "    speed_leave = []\n",
    "    \n",
    "    same_spec_cat = 0\n",
    "    sam_gen_cat = 0\n",
    "    all_venues = 0 \n",
    "    \n",
    "    #if new_venue not in venue_to_kas_status: \n",
    "        #continue\n",
    "    #status = venue_to_kas_status[new_venue]\n",
    "    status = venue_to_status[new_venue]\n",
    "    spec = venue_id_to_category_specific[new_venue]\n",
    "    gen = venue_id_to_category_general[new_venue]\n",
    "    \n",
    "    for surround_v in surrounding: \n",
    "        if surround_v in venue_inflow_transitions: \n",
    "            inflow_sum += venue_inflow_transitions[surround_v]\n",
    "        if surround_v in venue_outflow_transitions: \n",
    "            outflow_sum += venue_outflow_transitions[surround_v]\n",
    "        if surround_v in venue_distance_entering: \n",
    "            distance_enter.append(np.mean(venue_distance_entering[surround_v]))\n",
    "        if surround_v in venue_distance_leaving: \n",
    "            distance_leave.append(np.mean(venue_distance_leaving[surround_v]))\n",
    "        if surround_v in venue_speed_entering: \n",
    "            speed_enter.append(np.mean(venue_speed_entering[surround_v]))\n",
    "        if surround_v in venue_speed_leaving: \n",
    "            speed_leave.append(np.mean(venue_speed_leaving[surround_v]))\n",
    "        \n",
    "        spec_surr = venue_id_to_category_specific[surround_v]\n",
    "        gen_surr = venue_id_to_category_general[surround_v]\n",
    "        if spec_surr == same_spec_cat: \n",
    "            same_spec_cat += 1\n",
    "        if sam_gen_cat == gen_surr:\n",
    "            sam_gen_cat += 1\n",
    "        all_venues += 1\n",
    "       \n",
    "    dis_ent_mean = np.mean(distance_enter)\n",
    "    dis_ent_std = np.std(distance_enter)\n",
    "    dis_lea_mean = np.mean(distance_leave)\n",
    "    dis_lea_std =  np.std(distance_leave)\n",
    "    speed_ent_mean = np.mean(speed_enter)\n",
    "    speed_ent_std =  np.std(speed_enter)\n",
    "    speed_lea_mean = np.mean(speed_leave)\n",
    "    speed_lea_std =  np.std(speed_leave) \n",
    "     \n",
    "    entropy = srrdng_to_entropy[new_venue]\n",
    "    \n",
    "    index_spec = all_specific.index(spec)\n",
    "    index_gen = all_general.index(gen) \n",
    "    \n",
    "    inner = np.append(inner, count) \n",
    "    #inner = np.append(inner, within)\n",
    "    inner = np.append(inner, inflow_sum)\n",
    "    inner = np.append(inner, outflow_sum)    \n",
    "    #inner = np.append(inner, float(within) / inflow)\n",
    "    #inner = np.append(inner, float(within) / outflow)\n",
    "    if outflow_sum > 0: \n",
    "        inner = np.append(inner, float(inflow_sum) / outflow_sum)\n",
    "    else: \n",
    "        inner = np.append(inner, 0)\n",
    "    inner = np.append(inner, dis_ent_mean)  \n",
    "    inner = np.append(inner, dis_ent_std)\n",
    "    inner = np.append(inner, dis_lea_mean)\n",
    "    inner = np.append(inner, dis_lea_std)\n",
    "    inner = np.append(inner, speed_ent_mean)\n",
    "    inner = np.append(inner, speed_ent_std)\n",
    "    inner = np.append(inner, speed_lea_mean)\n",
    "    inner = np.append(inner, speed_lea_std)\n",
    "    \n",
    "    inner = np.append(inner, same_spec_cat)\n",
    "    inner = np.append(inner, sam_gen_cat)\n",
    "    inner = np.append(inner, all_venues)\n",
    "    if sam_gen_cat != 0:\n",
    "        inner = np.append(inner, float(same_spec_cat) / sam_gen_cat)\n",
    "    else:\n",
    "        inner = np.append(inner, 0)\n",
    "    if all_venues != 0:\n",
    "        inner = np.append(inner, float(sam_gen_cat) / all_venues)\n",
    "    else:\n",
    "        inner = np.append(inner, 0)\n",
    "        \n",
    "    inner = np.append(inner, entropy)\n",
    "    \n",
    "    inner = np.append(inner, index_spec)\n",
    "    inner = np.append(inner, index_gen)\n",
    "    \n",
    "    # output\n",
    "    inner = np.append(inner, status)  \n",
    "    myData = np.concatenate([myData, [inner]])   \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove nan\n",
    "# do as % change\n",
    "# need to downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing complete\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "myFile = open('features_updated_london.csv', 'w')\n",
    "with myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerows(myData)  \n",
    "print(\"Writing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
